# Finance Document RAG Pipeline

A comprehensive Retrieval-Augmented Generation (RAG) system for processing and querying 10,000 pages of financial documents with graphs, technical terms, and complex financial data.

## ğŸ—ï¸ Architecture Overview

```
User Query â†’ Query Rewriting â†’ Vector DB Search â†’ Re-ranking â†’ LLM Generation â†’ Response + References
```

## ğŸ“‹ Project Structure

```
finace_data_rag/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing/
â”‚   â”‚   â”œâ”€â”€ document_loader.py
â”‚   â”‚   â”œâ”€â”€ chunking_strategies.py
â”‚   â”‚   â”œâ”€â”€ multimodal_processor.py
â”‚   â”‚   â””â”€â”€ metadata_extractor.py
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”‚   â”œâ”€â”€ text_embeddings.py
â”‚   â”‚   â”œâ”€â”€ image_embeddings.py
â”‚   â”‚   â””â”€â”€ hybrid_embeddings.py
â”‚   â”œâ”€â”€ vector_db/
â”‚   â”‚   â”œâ”€â”€ pinecone_client.py
â”‚   â”‚   â”œâ”€â”€ weaviate_client.py
â”‚   â”‚   â”œâ”€â”€ qdrant_client.py
â”‚   â”‚   â””â”€â”€ vector_store_factory.py
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ query_rewriter.py
â”‚   â”‚   â”œâ”€â”€ hybrid_retriever.py
â”‚   â”‚   â”œâ”€â”€ reranker.py
â”‚   â”‚   â””â”€â”€ context_enhancer.py
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ llm_factory.py
â”‚   â”‚   â”œâ”€â”€ prompt_templates.py
â”‚   â”‚   â””â”€â”€ response_formatter.py
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ retrieval_metrics.py
â”‚   â”‚   â”œâ”€â”€ generation_metrics.py
â”‚   â”‚   â””â”€â”€ end_to_end_metrics.py
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ chat_endpoint.py
â”‚       â””â”€â”€ health_check.py
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.yaml
â”‚   â”œâ”€â”€ model_configs.yaml
â”‚   â””â”€â”€ vector_db_configs.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_documents/
â”‚   â”œâ”€â”€ processed_chunks/
â”‚   â””â”€â”€ metadata/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_chunking_analysis.ipynb
â”‚   â”œâ”€â”€ 03_embedding_comparison.ipynb
â”‚   â”œâ”€â”€ 04_retrieval_evaluation.ipynb
â”‚   â””â”€â”€ 05_end_to_end_testing.ipynb
â”œâ”€â”€ tests/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

1. **Setup Environment**
   ```bash
   pip install -r requirements.txt
   ```

2. **Configure Settings**
   - Update `config/settings.yaml` with your API keys
   - Configure vector database settings

3. **Process Documents**
   ```bash
   python src/data_processing/document_loader.py
   ```

4. **Run API Server**
   ```bash
   python src/api/main.py
   ```

## ğŸ“Š Key Features

- **Multi-modal Processing**: Handles text, tables, and images
- **Advanced Chunking**: Semantic and hybrid chunking strategies
- **Production Vector DB**: Scalable vector database solutions
- **Query Optimization**: Query rewriting and context enhancement
- **Re-ranking**: Advanced re-ranking for improved relevance
- **Comprehensive Evaluation**: Metrics at every pipeline stage
- **Reference Tracking**: Page/chapter/section number references

## ğŸ”§ Configuration

All configurations are managed through YAML files in the `config/` directory:
- Model selections and parameters
- Vector database configurations
- Embedding strategies
- Evaluation metrics

## ğŸ“ˆ Monitoring & Evaluation

Built-in evaluation metrics for:
- Retrieval accuracy (MRR, NDCG, Recall@K)
- Generation quality (BLEU, ROUGE, BERTScore)
- End-to-end performance
- Latency and throughput

## ğŸ”— Integration

- FastAPI for REST endpoints
- Docker support for deployment
- Monitoring with logging and metrics
- Extensible architecture for new components
